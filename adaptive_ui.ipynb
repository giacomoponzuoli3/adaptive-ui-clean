{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsdsqRFG3ARG"
      },
      "source": [
        "# Installation and Environment set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR1GxG93FAQl"
      },
      "source": [
        "## Clone Repository GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ri40vEFw4F1e"
      },
      "outputs": [],
      "source": [
        "!rm -rf sample_data/\n",
        "!rm -rf adaptive-ui-clean/\n",
        "!rm -rf /content/yolov8x-worldv2.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP0YuYjX24Tb",
        "outputId": "1234d387-43dc-4e1e-bc2f-2e980ca30f68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'adaptive-ui-clean'...\n",
            "remote: Enumerating objects: 351, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 351 (delta 31), reused 38 (delta 19), pack-reused 296 (from 1)\u001b[K\n",
            "Receiving objects: 100% (351/351), 81.98 MiB | 27.99 MiB/s, done.\n",
            "Resolving deltas: 100% (136/136), done.\n"
          ]
        }
      ],
      "source": [
        "# Download from github\n",
        "# if don't exist clone otherwise nothing\n",
        "!test -d adaptive-ui-clean || git clone https://github.com/giacomoponzuoli3/adaptive-ui-clean.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEm8BBnGF6uC"
      },
      "source": [
        "## Installation of dependences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YdTR_ri47Xg",
        "outputId": "af3b6f7f-3f09-4378-e4e2-bdbd3e709bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# installation of dependeces\n",
        "!pip -q install pyyaml numpy pandas matplotlib scikit-learn pillow opencv-python tqdm huggingface_hub datasets ultralytics ipdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxQYrsuGzHvt"
      },
      "source": [
        "# Generate Outdoor Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBv4H6rGzHvt"
      },
      "source": [
        "### Load outdoor video frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "collapsed": true,
        "id": "5vImvWsazHvt",
        "outputId": "0ff272a3-7a29-4434-d3b5-21c4691a2890"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1629150841.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Inserisci la tua token (https://huggingface.co/settings/tokens)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mHF_TOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hugging Face token (inizia con 'hf_'): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Sostituisci con l'ID della tua repo dataset privata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "from huggingface_hub import login, snapshot_download\n",
        "import os, shutil\n",
        "\n",
        "# Inserisci la tua token (https://huggingface.co/settings/tokens)\n",
        "HF_TOKEN = getpass(\"Hugging Face token (inizia con 'hf_'): \")\n",
        "\n",
        "# Sostituisci con l'ID della tua repo dataset privata\n",
        "REPO_ID = \"giacomoponzuoli3/adaptive-ui-outdoor-visibilty\"\n",
        "\n",
        "# sotto-cartella da scaricare\n",
        "# Sostituisci con l'ID della tua repo dataset privata\n",
        "REPO_ID = \"giacomoponzuoli3/adaptive-ui-outdoor-visibilty\"\n",
        "\n",
        "# sotto-cartella da scaricare\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1013143887256571\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1047767169978917\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1053053072788781\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1056705816066784\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1057018752751527\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1061673788897883\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1073662521104884\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1074684370674657\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1078840057577521\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1099703898158071\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1120809332737512\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1173135830437215\"\n",
        "\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1175008770223722\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1199721197750621\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1224828835384130\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1229774828171826\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1242752083704159\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1248321329927862\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1257470041836025\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1278104706677057\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1339440250346866\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1446119809363548\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1451016918850127\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1464501567592901\"\n",
        "\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1465376780791149\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1509670213005643\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1559491511615645\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1561241784806410\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1589968878220994\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1605877810280066\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1664858210911440\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1723524325073193\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1738061706941086\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1744890252715997\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1947994158971994\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_1983494342152387\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_2154197261640648\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_2263006570727110\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_2310784129296837\"\n",
        "\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_26910277515284456\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_2804873779681357\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_2861970153970966\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_2874281686067074\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_3338313216303419\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_335767442881471\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_3674709426113842\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_3883734215216970\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_419446457590567\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_438276488872707\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_463965796630125\"\n",
        "\n",
        "SUBPATH  = \"video_frames_outdoor/recording_481680718179172\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_495606053456369\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_496787149798594\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_505525682371994\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_506811838718054\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_507673755183320\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_513667388111193\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_522060430552651\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_525065940126690\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_526729470300043\"\n",
        "\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_539647728613813\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_539707968792900\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_546267671238100\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_547476497950519\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_548748957620690\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_554001616975921\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_557368980188448\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_571687658531728\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_720700043555459\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_802700365184064\"\n",
        "\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_8130327293763638\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_816953837180751\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_818457346852000\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_826729622984448\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_840656321614528\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_841348857780101\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_861114956160346\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_874434494665685\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_874635564610984\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_875754211162644\"\n",
        "\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_887417609494121\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_900851771949400\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_908313417343547\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_916014097065663\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_916391457066422\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_916515286984631\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_9262399620441214\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_946808614132107\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_950451000254505\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_971692201310931\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_982531483627587\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_993218322821802\"\n",
        "#SUBPATH  = \"video_frames_outdoor/recording_994355379105198\"\n",
        "\n",
        "# Cartella di destinazione in Colab\n",
        "LOCAL_DIR = \"/content/adaptive-ui-clean/data/\"\n",
        "\n",
        "# Login\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "# Scarica un'istantanea completa della repo (supporta anche LFS)\n",
        "snapshot_download(\n",
        "    repo_id=REPO_ID,\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=LOCAL_DIR,\n",
        "    local_dir_use_symlinks=False,  # copia file reali invece di symlink (più comodo su Colab)\n",
        "    allow_patterns=[f\"{SUBPATH}/**\"],    # <<— filtro SOLO quella sotto-cartella\n",
        "    token=HF_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCbxRqabzHvt"
      },
      "source": [
        "### Generate Single Istance (Test to try if all works correctly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkTZHVolzHvt",
        "outputId": "6340021a-228f-4d38-8246-ef2dc569e280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/adaptive-ui-clean/src/utils/gen_instance.py\", line 5, in <module>\n",
            "    from detectors import SaliencyDetector\n",
            "  File \"/content/adaptive-ui-clean/src/utils/detectors.py\", line 19, in <module>\n",
            "    from transformers import pipeline\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/__init__.py\", line 950, in <module>\n",
            "    import_structure = define_import_structure(Path(__file__).parent / \"models\", prefix=\"models\")\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\", line 2851, in define_import_structure\n",
            "    import_structure = create_import_structure_from_path(module_path)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\", line 2564, in create_import_structure_from_path\n",
            "    import_structure[f] = create_import_structure_from_path(os.path.join(module_path, f))\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\", line 2687, in create_import_structure_from_path\n",
            "    for _all_object in fetch__all__(file_content):\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\", line 2467, in fetch__all__\n",
            "    lines = file_content.splitlines()\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python /content/adaptive-ui-clean/src/utils/gen_instance.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys6xCnlxzHvu"
      },
      "source": [
        "### Generate Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1ELdGYbfzHvu",
        "outputId": "fd086baa-df0f-47bc-b44f-6dcf17b8f1ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758533670.866489   27009 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758533670.872548   27009 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758533670.894853   27009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758533670.894893   27009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758533670.894901   27009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758533670.894908   27009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-worldv2.pt to 'yolov8x-worldv2.pt': 100% ━━━━━━━━━━━━ 139.6MB 138.5MB/s 1.0s\n",
            "Fetching 1 files: 100% 1/1 [00:00<00:00, 3536.51it/s]\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/image_processing_base.py:410: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'reduce_labels'\n",
            "  image_processor = cls(**image_processor_dict)\n",
            "Device set to use cuda:0\n",
            "Found 3 videos: 1 train, 1 val, 1 test\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 cell phone, 81.7ms\n",
            "Speed: 4.2ms preprocess, 81.7ms inference, 40.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 cell phone, 103.0ms\n",
            "Speed: 3.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 cell phone, 103.4ms\n",
            "Speed: 3.2ms preprocess, 103.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 cell phone, 103.9ms\n",
            "Speed: 3.1ms preprocess, 103.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 cell phone, 103.8ms\n",
            "Speed: 3.2ms preprocess, 103.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 cell phone, 103.8ms\n",
            "Speed: 3.0ms preprocess, 103.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 cell phone, 104.0ms\n",
            "Speed: 3.8ms preprocess, 104.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 surfboard, 1 cell phone, 103.8ms\n",
            "Speed: 3.2ms preprocess, 103.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 1 car, 1 handbag, 1 cell phone, 103.9ms\n",
            "Speed: 3.3ms preprocess, 103.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 car, 1 cell phone, 102.9ms\n",
            "Speed: 4.9ms preprocess, 102.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "\n",
            "0: 640x640 1 person, 1 car, 1 bus, 1 cell phone, 103.9ms\n",
            "Speed: 3.0ms preprocess, 103.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/adaptive-ui-clean/src/utils/gen_dataset.py\", line 130, in <module>\n",
            "    dataset_gen.generate_dataset(\n",
            "  File \"/content/adaptive-ui-clean/src/utils/gen_dataset.py\", line 85, in generate_dataset\n",
            "    generated_instance_data = self.instance_generator.generate(frame, frame_path, eye_gaze_data, self.task)\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/adaptive-ui-clean/src/utils/gen_instance.py\", line 54, in generate\n",
            "    saliency_map = self.detector.get_combined_map(frame, frame_path, eye_gazes)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/adaptive-ui-clean/src/utils/detectors.py\", line 260, in get_combined_map\n",
            "    safety_and_social_acceptability_map = self.get_safety_and_social_acceptability_map(frame)\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/adaptive-ui-clean/src/utils/detectors.py\", line 72, in get_safety_and_social_acceptability_map\n",
            "    segments = self.seg_model(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/image_segmentation.py\", line 152, in __call__\n",
            "    return super().__call__(inputs, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 1467, in __call__\n",
            "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/base.py\", line 1475, in run_single\n",
            "    outputs = self.postprocess(model_outputs, **postprocess_params)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/pipelines/image_segmentation.py\", line 213, in postprocess\n",
            "    outputs = self.image_processor.post_process_semantic_segmentation(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/segformer/image_processing_segformer.py\", line 462, in post_process_semantic_segmentation\n",
            "    semantic_map = resized_logits[0].argmax(dim=0)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python /content/adaptive-ui-clean/src/utils/gen_dataset.py --task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud46TZttzHvu"
      },
      "source": [
        "### Upload outdoor dataset to Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO8k0pOAzHvu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import HfApi, create_repo, upload_folder\n",
        "\n",
        "# Paste a Write token from https://huggingface.co/settings/tokens\n",
        "token = getpass(\"🤖 Enter your Hugging Face token: \")\n",
        "login(token=token)\n",
        "print(\"Logged in.\")\n",
        "\n",
        "\n",
        "# CHANGE THESE\n",
        "USERNAME     = \"giacomoponzuoli3\"        # e.g., \"giacomolab\"\n",
        "REPO_NAME    = \"\"           # e.g., \"my-awesome-folder\"\n",
        "REPO_TYPE    = \"dataset\"              # \"dataset\" or \"model\"\n",
        "LOCAL_FOLDER = \"/content/adaptive-ui-clean/data/generated_overlays\"   # path to the folder you want to upload\n",
        "PRIVATE     = True                    # set False if you want it public\n",
        "\n",
        "repo_id = f\"{USERNAME}/{REPO_NAME}\"\n",
        "assert os.path.isdir(LOCAL_FOLDER), f\"Folder not found: {LOCAL_FOLDER}\"\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# Create the repo if it doesn't exist\n",
        "create_repo(\n",
        "    repo_id=repo_id,\n",
        "    repo_type=REPO_TYPE,\n",
        "    private=PRIVATE,\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "# Optional: create a minimal README.md if absent (dataset card)\n",
        "readme_path = os.path.join(LOCAL_FOLDER, \"README.md\")\n",
        "if not os.path.exists(readme_path) and REPO_TYPE == \"dataset\":\n",
        "    with open(readme_path, \"w\") as f:\n",
        "        f.write(f\"# {REPO_NAME}\\n\\nUploaded from Google Colab.\\n\")\n",
        "\n",
        "# Upload the whole folder\n",
        "upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    repo_type=REPO_TYPE,\n",
        "    folder_path=LOCAL_FOLDER,\n",
        "    path_in_repo=\".\",                        # upload into repo root\n",
        "    commit_message=\"Add folder from Colab\",\n",
        "    ignore_patterns=[\"**/.ipynb_checkpoints/**\", \"**/__pycache__/**\"]\n",
        ")\n",
        "\n",
        "print(f\"Upload complete: https://huggingface.co/{repo_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFjcllrnzHvu"
      },
      "source": [
        "## Download Outdoor video frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXDXpSnZ7sbw"
      },
      "source": [
        "## Download Indoor Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFEZ0FY9zHvu"
      },
      "outputs": [],
      "source": [
        "\n",
        "from getpass import getpass\n",
        "from huggingface_hub import login, snapshot_download\n",
        "import os, shutil\n",
        "\n",
        "# Inserisci la tua token (https://huggingface.co/settings/tokens)\n",
        "HF_TOKEN = getpass(\"Hugging Face token (inizia con 'hf_'): \")\n",
        "\n",
        "# Sostituisci con l'ID della tua repo dataset privata\n",
        "REPO_ID = \"giacomoponzuoli3/adaptive-ui-data\"\n",
        "\n",
        "# Cartella di destinazione in Colab\n",
        "LOCAL_DIR = \"/content/adaptive-ui-clean/data/generated_overlays\"\n",
        "\n",
        "# Login\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "# Pulisce eventuali download precedenti (opzionale)\n",
        "if os.path.exists(LOCAL_DIR):\n",
        "    shutil.rmtree(LOCAL_DIR)\n",
        "\n",
        "# Scarica un'istantanea completa della repo (supporta anche LFS)\n",
        "snapshot_download(\n",
        "    repo_id=REPO_ID,\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=LOCAL_DIR,\n",
        "    local_dir_use_symlinks=False,  # copia file reali invece di symlink (più comodo su Colab)\n",
        "    token=HF_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THXksTUfzHvu"
      },
      "source": [
        "# Visibility Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzPIcJ1LzHvu"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Ro5zzlzHvu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSBs8c08zHvu"
      },
      "source": [
        "## Evalutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zrWpIzqzHvu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fjzLGLwzHvu"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4CK2sxyzHvv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
